# -*- coding: utf-8 -*-
"""
Created on Tue May 28 12:52:30 2019

@author: 15201002
"""

import numpy as np  
import matplotlib.pyplot as plt  
import pandas as pd  
import numpy as np
import warnings
warnings.filterwarnings('ignore')

data=pd.read_csv('Thesis_responses_Scaled.csv')
#print(data.head)

X=data.iloc[:,1:60].values
y=data.Flag.values
#y=data.iloc[:,50].values
print(y)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(X_train)

X_train=scaler.transform(X_train)
X_test=scaler.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
classifier=KNeighborsClassifier(n_neighbors=6)
classifier.fit(X_train,y_train)

y_pred=classifier.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))

error = []

# Calculating error for K values between 1 and 40
for i in range(1, 40):  
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    pred_i = knn.predict(X_test)
    error.append(np.mean(pred_i != y_test))
    
plt.figure(figsize=(12, 6))  
plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',  
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')  
plt.xlabel('K Value')  
plt.ylabel('Mean Error')  

print("-----------------------Graph Part-----------------------------")

cm=confusion_matrix(y_test,y_pred)
tn=cm[0,0]
fp=cm[0,1]
fn=cm[1,0]
tp=cm[1,1]
print('Sensitivity:',tp/(tp+fn))
print('Specificity:',tn/(tn+fp))
print('Precision:',tp/(tp+fp))
print('Negative predictive value:',tn/(tn+fn))
print('Accuracy=',((tn+tp)*100)/(tn+tp+fn+fp))
from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
fpr=dict()
tpr=dict()
roc_auc=dict()
fpr[0],tpr[0],_=roc_curve(y_test,y_pred)
roc_auc[0]=auc(fpr[0],tpr[0])

fpr["micro"],tpr["micro"],_=roc_curve(y_test.ravel(),y_pred.ravel())
roc_auc["micro"]=auc(fpr["micro"],tpr["micro"])

plt.figure()
lw = 2
plt.plot(fpr[0], tpr[0], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
print('Accuracy=',((tn+tp)*100)/(tn+tp+fn+fp))