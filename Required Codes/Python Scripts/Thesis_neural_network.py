import pandas as pd
import numpy as np
import warnings
from keras.layers import LeakyReLU
warnings.filterwarnings('ignore')
import time
import matplotlib.pyplot as plt

#time measurement starts
start = time.time()

dataset=pd.read_csv("Thesis_responses_Scaled.csv")
#
print(dataset.head())
X=dataset.iloc[:,1:60].values
y=dataset.Flag.values

print(y)

#dataset=pd.read_csv("Alpha_Test.csv")
#
#print(dataset.head())
#X=dataset.iloc[:,0:40].values
#y=dataset.iloc[:,40].values
#
#print(y)

from sklearn.model_selection import train_test_split

# Split the data up in train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=43)

# Import `StandardScaler` from `sklearn.preprocessing`
from sklearn.preprocessing import StandardScaler

# Define the scaler 
scaler = StandardScaler()

# Scale the train set
X_train = scaler.fit_transform(X_train)

# Scale the test set
X_test = scaler.fit_transform(X_test)

# Import `Sequential` from `keras.models`
from keras.models import Sequential

# Import `Dense` from `keras.layers`
from keras.layers import Dense

# Initialize the constructor
model = Sequential()

# Add an input layer 
model.add(Dense(60, activation='relu', input_shape=(59,)))

# Add multiple hidden layer 
model.add(Dense(20, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(LeakyReLU(alpha=0.1))

# Add an output layer 
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
                   
model.fit(X_train, y_train,epochs=50, batch_size=1, verbose=1)

y_pred = model.predict(X_test)

score = model.evaluate(X_test, y_test,verbose=1)

print(score)

# Confusion matrix
from sklearn.metrics import classification_report,confusion_matrix,matthews_corrcoef 
cm=confusion_matrix(y_test, y_pred.round())
print(classification_report(y_test,y_pred.round()))
print("The Matthews correlation coefficient ",matthews_corrcoef(y_test,y_pred.round()))
print(cm)
tn=cm[0,0]
fp=cm[0,1]
fn=cm[1,0]
tp=cm[1,1]
print('Sensitivity:',tp/(tp+fn))
print('Specificity:',tn/(tn+fp))
print('Precision:',tp/(tp+fp))
print('Negative predictive value:',tn/(tn+fn))
print('Accuracy=',((tn+tp)*100)/(tn+tp+fn+fp))

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
fpr=dict()
tpr=dict()
roc_auc=dict()
fpr[0],tpr[0],_=roc_curve(y_test,y_pred)
roc_auc[0]=auc(fpr[0],tpr[0])

fpr["micro"],tpr["micro"],_=roc_curve(y_test.ravel(),y_pred.ravel())
roc_auc["micro"]=auc(fpr["micro"],tpr["micro"])

plt.figure()
lw = 2
plt.plot(fpr[0], tpr[0], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic of NN')
plt.legend(loc="lower right")
plt.show()
print('Accuracy=',((tn+tp)*100)/(tn+tp+fn+fp))

end=time.time()
print("Time required ",end-start)